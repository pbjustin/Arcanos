# ================================
# OPENAI INTEGRATION (REQUIRED)
# ================================

# OpenAI API Key - REQUIRED for all AI functionality
# Get from: https://platform.openai.com/api-keys
# Supported environment variable names (in priority order):
#   1. OPENAI_API_KEY (recommended - OpenAI SDK standard)
#   2. RAILWAY_OPENAI_API_KEY (Railway-specific override)
OPENAI_API_KEY=your-openai-api-key-here

# Primary AI Model Configuration
# Default: Fine-tuned Arcanos v2 model
# Latest stable alternatives: gpt-4o (recommended), gpt-4o-mini (cost-effective)
# Legacy models (not recommended): gpt-4-turbo, gpt-3.5-turbo
# Supported environment variable names (in priority order):
#   1. OPENAI_MODEL (recommended - OpenAI SDK standard)
#   2. AI_MODEL (legacy, still supported)
#   3. FINETUNED_MODEL_ID (legacy alias for Railway compatibility)
#   4. RAILWAY_OPENAI_MODEL (Railway-specific override)
OPENAI_MODEL=gpt-4o-mini
OPENAI_VISION_MODEL=gpt-4o
# Backend complex tasks (e.g. final ARCANOS stage after reasoning). Default: gpt-4o
OPENAI_COMPLEX_MODEL=gpt-4o
# Optional fallback model for resiliency when primary model fails
# FALLBACK_MODEL=gpt-4o-mini
# Legacy alias for fallback model
# AI_FALLBACK_MODEL=gpt-4o-mini
TEMPERATURE=0.7
MAX_TOKENS=500
# Backend fine-tuned model: set in Railway dashboard or .env (e.g. FINETUNED_MODEL_ID or AI_MODEL)
# AI_MODEL=

# Override the default system prompt for general completions
OPENAI_SYSTEM_PROMPT=You are a helpful AI assistant.

# OpenAI Responses cache TTL (milliseconds) and retry budget for API calls
OPENAI_CACHE_TTL_MS=300000
OPENAI_MAX_RETRIES=3

# Token limit for generating enhanced image prompts before image creation
OPENAI_IMAGE_PROMPT_TOKEN_LIMIT=256

# Default max tokens for general prompt completions (fallback when not specified)
OPENAI_DEFAULT_MAX_TOKENS=256

# OpenAI Completion Default Parameters
# Temperature controls randomness: 0 = deterministic, 2 = very random (default: 0.7)
# OPENAI_DEFAULT_TEMPERATURE=0.7
# Top_p controls diversity via nucleus sampling (default: 1)
# OPENAI_DEFAULT_TOP_P=1
# Frequency penalty reduces repetition of token sequences (default: 0)
# OPENAI_DEFAULT_FREQUENCY_PENALTY=0
# Presence penalty encourages talking about new topics (default: 0)
# OPENAI_DEFAULT_PRESENCE_PENALTY=0

# OpenAI Base URL Override (Advanced)
# Override the default OpenAI API base URL (useful for proxies or Azure OpenAI)
# Leave blank to use default: https://api.openai.com/v1
# Supported environment variable names:
#   1. OPENAI_BASE_URL (recommended - OpenAI SDK standard)
#   2. OPENAI_API_BASE_URL (alternative)
#   3. OPENAI_API_BASE (legacy alias)
# OPENAI_BASE_URL=
# OPENAI_API_BASE=

# Dedicated Research Model Override
# Leave blank to reuse AI_MODEL; set to your fine-tuned research model ID when available
RESEARCH_MODEL_ID=

# Routing token limit override for centralized completions (default: 4096)
ROUTING_MAX_TOKENS=4096

# GPT-5.1 Model Configuration (Advanced Features)
# Used for orchestration and complex reasoning tasks
# Note: Update to 'gpt-5.1' when generally available
GPT5_MODEL=gpt-5
# GPT-5.1 explicit model override (preferred when available)
# GPT51_MODEL=gpt-5.1

# Token Limits for Specialized Endpoints
# Backstage booking prompt token limit
BOOKER_TOKEN_LIMIT=512
# Default token limit for tutor queries
TUTOR_DEFAULT_TOKEN_LIMIT=200

# Image generation model (default: gpt-image-1)
IMAGE_MODEL=gpt-image-1
# Default image size for generation responses
IMAGE_DEFAULT_SIZE=1024x1024

# Allow mock OpenAI responses for CI/dev-only usage
# ALLOW_MOCK_OPENAI=false
